{"version":3,"file":"emphasis.js","sources":["../../../../../../../../../node_modules/.pnpm/markdown-it@14.1.0/node_modules/markdown-it/lib/rules_inline/emphasis.mjs"],"sourcesContent":["// Process *this* and _that_\n//\n\n// Insert each marker as a separate text token, and add it to delimiter list\n//\nfunction emphasis_tokenize (state, silent) {\n  const start = state.pos\n  const marker = state.src.charCodeAt(start)\n\n  if (silent) { return false }\n\n  if (marker !== 0x5F /* _ */ && marker !== 0x2A /* * */) { return false }\n\n  const scanned = state.scanDelims(state.pos, marker === 0x2A)\n\n  for (let i = 0; i < scanned.length; i++) {\n    const token = state.push('text', '', 0)\n    token.content = String.fromCharCode(marker)\n\n    state.delimiters.push({\n      // Char code of the starting marker (number).\n      //\n      marker,\n\n      // Total length of these series of delimiters.\n      //\n      length: scanned.length,\n\n      // A position of the token this delimiter corresponds to.\n      //\n      token: state.tokens.length - 1,\n\n      // If this delimiter is matched as a valid opener, `end` will be\n      // equal to its position, otherwise it's `-1`.\n      //\n      end: -1,\n\n      // Boolean flags that determine if this delimiter could open or close\n      // an emphasis.\n      //\n      open: scanned.can_open,\n      close: scanned.can_close\n    })\n  }\n\n  state.pos += scanned.length\n\n  return true\n}\n\nfunction postProcess (state, delimiters) {\n  const max = delimiters.length\n\n  for (let i = max - 1; i >= 0; i--) {\n    const startDelim = delimiters[i]\n\n    if (startDelim.marker !== 0x5F/* _ */ && startDelim.marker !== 0x2A/* * */) {\n      continue\n    }\n\n    // Process only opening markers\n    if (startDelim.end === -1) {\n      continue\n    }\n\n    const endDelim = delimiters[startDelim.end]\n\n    // If the previous delimiter has the same marker and is adjacent to this one,\n    // merge those into one strong delimiter.\n    //\n    // `<em><em>whatever</em></em>` -> `<strong>whatever</strong>`\n    //\n    const isStrong = i > 0 &&\n               delimiters[i - 1].end === startDelim.end + 1 &&\n               // check that first two markers match and adjacent\n               delimiters[i - 1].marker === startDelim.marker &&\n               delimiters[i - 1].token === startDelim.token - 1 &&\n               // check that last two markers are adjacent (we can safely assume they match)\n               delimiters[startDelim.end + 1].token === endDelim.token + 1\n\n    const ch = String.fromCharCode(startDelim.marker)\n\n    const token_o   = state.tokens[startDelim.token]\n    token_o.type    = isStrong ? 'strong_open' : 'em_open'\n    token_o.tag     = isStrong ? 'strong' : 'em'\n    token_o.nesting = 1\n    token_o.markup  = isStrong ? ch + ch : ch\n    token_o.content = ''\n\n    const token_c   = state.tokens[endDelim.token]\n    token_c.type    = isStrong ? 'strong_close' : 'em_close'\n    token_c.tag     = isStrong ? 'strong' : 'em'\n    token_c.nesting = -1\n    token_c.markup  = isStrong ? ch + ch : ch\n    token_c.content = ''\n\n    if (isStrong) {\n      state.tokens[delimiters[i - 1].token].content = ''\n      state.tokens[delimiters[startDelim.end + 1].token].content = ''\n      i--\n    }\n  }\n}\n\n// Walk through delimiter list and replace text tokens with tags\n//\nfunction emphasis_post_process (state) {\n  const tokens_meta = state.tokens_meta\n  const max = state.tokens_meta.length\n\n  postProcess(state, state.delimiters)\n\n  for (let curr = 0; curr < max; curr++) {\n    if (tokens_meta[curr] && tokens_meta[curr].delimiters) {\n      postProcess(state, tokens_meta[curr].delimiters)\n    }\n  }\n}\n\nexport default {\n  tokenize: emphasis_tokenize,\n  postProcess: emphasis_post_process\n}\n"],"names":["emphasis_tokenize","state","silent","start","marker","scanned","i","token","postProcess","delimiters","max","startDelim","endDelim","isStrong","ch","token_o","token_c","emphasis_post_process","tokens_meta","curr","r_emphasis"],"mappings":"aAKA,SAASA,EAAmBC,EAAOC,EAAQ,CACzC,MAAMC,EAAQF,EAAM,IACdG,EAASH,EAAM,IAAI,WAAWE,CAAK,EAIzC,GAFID,GAEAE,IAAW,IAAgBA,IAAW,GAAgB,MAAO,GAEjE,MAAMC,EAAUJ,EAAM,WAAWA,EAAM,IAAKG,IAAW,EAAI,EAE3D,QAASE,EAAI,EAAGA,EAAID,EAAQ,OAAQC,IAAK,CACvC,MAAMC,EAAQN,EAAM,KAAK,OAAQ,GAAI,CAAC,EACtCM,EAAM,QAAU,OAAO,aAAaH,CAAM,EAE1CH,EAAM,WAAW,KAAK,CAGpB,OAAAG,EAIA,OAAQC,EAAQ,OAIhB,MAAOJ,EAAM,OAAO,OAAS,EAK7B,IAAK,GAKL,KAAMI,EAAQ,SACd,MAAOA,EAAQ,SACrB,CAAK,CACF,CAED,OAAAJ,EAAM,KAAOI,EAAQ,OAEd,EACT,CAEA,SAASG,EAAaP,EAAOQ,EAAY,CACvC,MAAMC,EAAMD,EAAW,OAEvB,QAASH,EAAII,EAAM,EAAGJ,GAAK,EAAGA,IAAK,CACjC,MAAMK,EAAaF,EAAWH,CAAC,EAO/B,GALIK,EAAW,SAAW,IAAeA,EAAW,SAAW,IAK3DA,EAAW,MAAQ,GACrB,SAGF,MAAMC,EAAWH,EAAWE,EAAW,GAAG,EAOpCE,EAAWP,EAAI,GACVG,EAAWH,EAAI,CAAC,EAAE,MAAQK,EAAW,IAAM,GAE3CF,EAAWH,EAAI,CAAC,EAAE,SAAWK,EAAW,QACxCF,EAAWH,EAAI,CAAC,EAAE,QAAUK,EAAW,MAAQ,GAE/CF,EAAWE,EAAW,IAAM,CAAC,EAAE,QAAUC,EAAS,MAAQ,EAE/DE,EAAK,OAAO,aAAaH,EAAW,MAAM,EAE1CI,EAAYd,EAAM,OAAOU,EAAW,KAAK,EAC/CI,EAAQ,KAAUF,EAAW,cAAgB,UAC7CE,EAAQ,IAAUF,EAAW,SAAW,KACxCE,EAAQ,QAAU,EAClBA,EAAQ,OAAUF,EAAWC,EAAKA,EAAKA,EACvCC,EAAQ,QAAU,GAElB,MAAMC,EAAYf,EAAM,OAAOW,EAAS,KAAK,EAC7CI,EAAQ,KAAUH,EAAW,eAAiB,WAC9CG,EAAQ,IAAUH,EAAW,SAAW,KACxCG,EAAQ,QAAU,GAClBA,EAAQ,OAAUH,EAAWC,EAAKA,EAAKA,EACvCE,EAAQ,QAAU,GAEdH,IACFZ,EAAM,OAAOQ,EAAWH,EAAI,CAAC,EAAE,KAAK,EAAE,QAAU,GAChDL,EAAM,OAAOQ,EAAWE,EAAW,IAAM,CAAC,EAAE,KAAK,EAAE,QAAU,GAC7DL,IAEH,CACH,CAIA,SAASW,EAAuBhB,EAAO,CACrC,MAAMiB,EAAcjB,EAAM,YACpBS,EAAMT,EAAM,YAAY,OAE9BO,EAAYP,EAAOA,EAAM,UAAU,EAEnC,QAASkB,EAAO,EAAGA,EAAOT,EAAKS,IACzBD,EAAYC,CAAI,GAAKD,EAAYC,CAAI,EAAE,YACzCX,EAAYP,EAAOiB,EAAYC,CAAI,EAAE,UAAU,CAGrD,CAEA,MAAeC,EAAA,CACb,SAAUpB,EACV,YAAaiB,CACf","x_google_ignoreList":[0]}